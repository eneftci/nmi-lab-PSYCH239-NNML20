<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js – NNML 2020</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/nmilab.css" id="theme">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
    <link rel="stylesheet" type="text/css" href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="lib/css/monokai.css">

    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.0.0/animate.min.css"
    />
    <link rel="stylesheet" href="reveal.js-plugins/appearance/appearance.css" />

    
    <link rel="stylesheet" href="plugin/highlight/monokai.css"  id="highlight-theme"  />
<!-- Printing and PDF exports -->
<script>
  var link = document.createElement( 'link' );
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
  document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>


<script>
  //function for evaluation
  function solve()
  {
          let w0 = document.getElementById("w0").value
          let w1 = document.getElementById("w1").value
          let b = document.getElementById("b").value
          document.getElementById("a11").innerHTML = (eval(w0)*1+eval(w1)*1+eval(b)).toFixed(2)
          document.getElementById("a10").innerHTML = (eval(w0)*1+eval(w1)*0+eval(b)).toFixed(2)
          document.getElementById("a01").innerHTML = (eval(w0)*0+eval(w1)*1+eval(b)).toFixed(2)
          document.getElementById("a00").innerHTML = (eval(w0)*0+eval(w1)*0+eval(b)).toFixed(2)
          document.getElementById("y11").innerHTML = (((eval(w0)*1+eval(w1)*1+eval(b))>0)*1)
          document.getElementById("y10").innerHTML = (((eval(w0)*1+eval(w1)*0+eval(b))>0)*1)
          document.getElementById("y01").innerHTML = (((eval(w0)*0+eval(w1)*1+eval(b))>0)*1)
          document.getElementById("y00").innerHTML = (((eval(w0)*0+eval(w1)*0+eval(b))>0)*1)
          document.getElementById('w0val').innerHTML=eval(w0); 
          document.getElementById('w1val').innerHTML=eval(w1); 
          document.getElementById('bval').innerHTML=eval(b); 
        }

</script>



<script async defer src="https://buttons.github.io/buttons.js"></script>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

        <section data-external="title.html" data-vertical-align-top data-background-color=#B2BA67 ></section>
        <section data-markdown data-vertical-align-top data-background-color=#B2BA67><textarea data-template>
            <h1> Lecture #: Class Title <br/> </h1>

        </textarea></section>

        <section data-markdown><textarea data-template>
        <h2> Feed-Forward vs. Recurrent Networks</h2>                                                     
        <ul>
          <li/> Due to the difficulties of training recurrent neural networks, they are now falling out of favor. 
          <li/> The State-of-the-art language and audio are feed-forward networks
        </ul>
        </textarea></section>

        <section data-markdown><textarea data-template>
        <h2> Feed-Forward Example For Time-Dependent Data: WaveNet</h2>
        <ul>
          <li/> Wavenet is a type of feedforward Convnet. It uses convolutions "à trous" to obtain large receptive fields
        <div class=row>
          <div class=column>
            <img src="images/dilation.gif" />
          </div>
          <div class=column>
            <img src="images/dilated_wavenet.png" />
          </div>
        </div>
        <p class=ref> Van der Oord et al. 2016</p>
          <li/> Learns generative model: 
            $$
            p(\mathbf{x}) = \prod_t p(x_t|x_{t-1}, ..., x_0)
            $$
            <li/> Wavenets are the state-of-the-art in audio generation. See <a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio"> Google's blog </a>.
        </ul>
        </textarea></section>

        <section data-markdown><textarea data-template>
        <h2> Feed-Forward Example For Time-Dependent Data: BERT </h2>
        <ul>
          <li/> Bert is the state-of-the-art in language modeling. It uses a feedforward "transformers with "self-attention block" to learn relations across text
        <div class=row>
          <div class=column>
            <img src="images/self-attention-block.png" />
          </div>
          <div class=column>
            <img src="images/bert.png" />
          </div>
        </div>
        <p class=ref> Van der Oord et al. 2016</p>
          <li/> Trained to predict missing words: ("My dog is [MASK]", predict target "Hairy") and next sentence prediction
        <div class=row>
          <div class=column>
        <blockquote>
        the man went to [MASK] store [SEP] he bought a gallon [MASK] milk 

        Label = IsNext
        </blockquote>
          </div>
          <div class=column>
        <blockquote>
        the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds 

        Label = NotNext
        </blockquote>
          </div>
        </div>
        <li/> Wavenets are the state-of-the-art in audio generation. See <a href="https://deepmind.com/blog/article/wavenet-generative-model-raw-audio"> Google's blog </a>.
        </ul>
        </textarea></section>



      </div>
    </div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/zoom/zoom.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/math/math.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
    <script src="reveal.js-plugins/menu/menu.js"></script>
    <script src="reveal.js-plugins/audio-slideshow/plugin.js"></script>
    <script src="reveal.js-plugins/audio-slideshow/recorder.js"></script>
    <script src="reveal.js-plugins/audio-slideshow/RecordRTC.js"></script>
    <script src="reveal.js-plugins/chalkboard/plugin.js"></script>
    <script src="reveal.js-plugins/external/external.js"></script>
    <script src="reveal.js-plugins/externalcode/externalcode.js"></script>
    <script src="reveal.js-plugins/appearance/appearance.js"></script>

		<script>
      Reveal.configure({ pdfMaxPagesPerSlide: 1, hash: true, slideNumber: true})
			// Also available as an ES module, see:
			// https://revealjs.com/initialization/
			Reveal.initialize({
        mouseWheel: false,
        width: 1280,
        height: 720,
        margin: 0.0,
        navigationMode: 'grid',
        transition: 'fade',
				controls: true,
				progress: true,
				center: true,
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [Appearance, RevealZoom, RevealSearch, RevealMarkdown, RevealHighlight, RevealAudioRecorder, RevealAudioSlideshow, RevealMath, RevealExternal, Externalcode, RevealMenu],

      	menu: { // Menu works best with font-awesome installed: sudo apt-get install fonts-font-awesome
					themes: false,
					transitions: false,
					markers: true,
					hideMissingTitles: true,
					custom: [
				            { title: 'Plugins', icon: '<i class="fa fa-external-link-alt"></i>', src: 'toc.html' },
				            { title: 'About', icon: '<i class="fa fa-info"></i>', src: 'about.html' }
				        ]
				},

      audio: {
        prefix: 'audio/', 	// audio files are stored in the "audio" folder
        suffix: '.ogg',		// audio files have the ".ogg" ending
        textToSpeechURL: null,  // the URL to the text to speech converter
        defaultNotes: false, 	// use slide notes as default for the text to speech converter
        defaultText: false, 	// use slide text as default for the text to speech converter
        advance: 300, 		// advance to next slide after given time in milliseconds after audio has played, use negative value to not advance
        autoplay: false,	// automatically start slideshow
        defaultDuration: 1.0,	// default duration in seconds if no audio is available
        defaultAudios: true,	// try to play audios with names such as audio/1.2.ogg
        playerOpacity: 0.5,	// opacity value of audio player if unfocused
        playerStyle: 'position: fixed; bottom: 4px; left: 25%; width: 50%; height:75px; z-index: 33;', // style used for container of audio controls
        startAtFragment: false, // when moving to a slide, start at the current fragment or at the start of the slide
      },
      // ...


				keyboard: { 
					82: function() { Recorder.toggleRecording(); },	// press 'r' to start/stop recording
					90: function() { Recorder.downloadZip(); }, 	// press 'z' to download zip containing audio files
					84: function() { Recorder.fetchTTS(); } 	// press 't' to fetch TTS audio files
  				}


    });
		</script>


	</body>
</html>
